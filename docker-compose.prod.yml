version: '3.8'

services:
  db:
    image: pgvector/pgvector:pg16
    container_name: ai_agent_postgres_db_prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
    # ports: # Not exposed directly, only to internal network
    #   - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    # logging: # Example logging configuration
    #   driver: "json-file"
    #   options:
    #     max-size: "10m"
    #     max-file: "3"
    # deploy: # Example resource limits (more effective with Docker Swarm or K8s)
    #   resources:
    #     limits:
    #       cpus: '0.50'
    #       memory: 512M

  redis:
    image: redis:6-alpine
    container_name: ai_agent_redis_prod
    # ports: # Not exposed directly
    #   - "6379:6379"
    command: redis-server --save 60 1 --loglevel warning # Example: persist data, reduce log level
    volumes:
      - redis_data_prod:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '0.25'
    #       memory: 256M

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      # args: # Example build arguments if needed for prod
      #   APP_ENV: production
    container_name: ai_agent_backend_service_prod
    # For production, consider Gunicorn or a similar robust ASGI server
    # command: gunicorn -k uvicorn.workers.UvicornWorker -w 4 -b 0.0.0.0:8000 app.main:app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 # Sticking with uvicorn for simplicity
    # volumes: # No code mounting for production
    #   - ./backend/app:/app/app
    # ports: # Not exposed directly
    #   - "8000:8000"
    environment:
      DATABASE_URL: ${DATABASE_URL}
      SECRET_KEY: ${SECRET_KEY} # CRITICAL: Should be a strong, unique key for production
      ALGORITHM: ${ALGORITHM}
      ACCESS_TOKEN_EXPIRE_MINUTES: ${ACCESS_TOKEN_EXPIRE_MINUTES}
      # Ensure any other necessary env vars are set (e.g., from root .env or injected)
      LOG_LEVEL: INFO # Example
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    env_file:
      - .env # Load variables from root .env file
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '1.0' # Example: 1 CPU core
    #       memory: 1G

  ai_agent:
    build:
      context: ./ai-agent
      dockerfile: Dockerfile
    container_name: ai_agent_core_service_prod
    command: uvicorn app.main:app --host 0.0.0.0 --port 8001 # No reload for prod
    # volumes: # No code mounting
    #   - ./ai-agent/app:/app/app
    # ports: # Not exposed directly
    #   - "8001:8001"
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY} # CRITICAL
      DATABASE_URL: ${DATABASE_URL} # For pgvector
      REDIS_HOST: ${REDIS_HOST:-redis}
      REDIS_PORT: ${REDIS_PORT:-6379}
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      MAX_CHAT_TURNS_HISTORY: ${MAX_CHAT_TURNS_HISTORY:-10} # Potentially larger history for prod
      PINECONE_VECTOR_DIMENSION: ${PINECONE_VECTOR_DIMENSION:-1536} # For OpenAI embedding dim
      LOG_LEVEL: INFO
    depends_on:
      db: # For pgvector
        condition: service_healthy
      redis: # For chat history
        condition: service_healthy
    restart: unless-stopped
    env_file:
      - .env
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '1.0'
    #       memory: 1G

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile # This Dockerfile builds React app and uses Nginx to serve
      # args: # Pass build-time args to React app if needed
      #   REACT_APP_API_BASE_URL: /api/v1/backend # Already handled by env vars at runtime for apiService.js
      #   REACT_APP_AI_AGENT_API_BASE_URL: /api/v1/agent
    container_name: ai_agent_frontend_prod
    # ports: # Not exposed directly
    #   - "80:80" # Its internal Nginx serves on port 80
    restart: unless-stopped
    # No environment variables needed here at runtime if using static build,
    # unless the entrypoint/CMD in frontend/Dockerfile uses them.
    # The REACT_APP_* vars are build-time for CRA, but our Nginx gateway makes them runtime-agnostic.
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '0.25'
    #       memory: 128M # For serving static files with Nginx

  nginx_gateway:
    build:
      context: ./nginx
      dockerfile: Dockerfile # This Dockerfile now copies nginx.prod.conf by default
    container_name: ai_agent_nginx_gateway_prod
    ports:
      - "80:80" # Main entry point for HTTP traffic
      # - "443:443" # Uncomment if SSL is configured and handled by this Nginx
    depends_on:
      - backend
      - ai_agent
      - frontend
    volumes:
      # - ./nginx/nginx.prod.conf:/etc/nginx/conf.d/default.conf:ro # Already copied by Dockerfile
      # Mount SSL certs for production:
      # - /path/to/your/prod/ssl_certs:/etc/nginx/ssl:ro
      - nginx_logs_prod:/var/log/nginx
    restart: unless-stopped
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '0.50'
    #       memory: 256M

volumes:
  postgres_data_prod:
  redis_data_prod:
  nginx_logs_prod:

# Note on .env file for production:
# A separate .env file (e.g., .env.prod) should be created and secured.
# It should contain actual production secrets and configurations.
# To use it: docker-compose -f docker-compose.prod.yml --env-file .env.prod up -d
# Or, manage secrets via the deployment environment (e.g., AWS Secrets Manager, ECS task definitions).
# For this project, we assume the root .env file will be populated with production values when using this file.
# CRITICAL: Ensure SECRET_KEY, OPENAI_API_KEY, POSTGRES_PASSWORD etc. are strong and unique for production.
